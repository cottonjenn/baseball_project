[
  {
    "objectID": "Tutorial.html",
    "href": "Tutorial.html",
    "title": "Getting Started",
    "section": "",
    "text": "Here is how you use my package:\nFor the first part of the package use, we will import the first function for scraping the baseball hitting statistics. This will allow you to scrape the players’ statistics from the baseball-reference site.\n\nimport sys\nimport os\nsys.path.append(os.path.abspath(\"src\"))\nfrom bbanalysis.gathering_stats import scrape_batting_data\n\nURLS = ['https://www.baseball-reference.com/leagues/majors/2018-standard-batting.shtml']\ntest = scrape_batting_data(URLS)\n\n\nScraping 2018...\n  1272 players scraped for 2018\n\n\nNow we will do the second function which allows you to clean the data. Again, this is just the statistical data, not the salary data.\n\nimport pandas as pd\nfrom bbanalysis.gathering_stats import clean_batting_data\n\n# df = [1,2,3,4,5]\n# clean_batting_data(test)\n\n# Convert list of dicts to DataFrame\ntest_df = pd.DataFrame(test)\n# test_df.head()\n# Pass the DataFrame directly (NOT as a list)\ncleaned_data = clean_batting_data(test_df)\ncleaned_data.head()\n\n\n\n\n\n\n\n\nYear\nRk\nPlayer\nPlayer_Link\nAge\nTeam\nLg\nWAR\nG\nPA\n...\nrOBA\nRbat+\nTB\nGIDP\nHBP\nSH\nSF\nIBB\nPos\nbatting_hand\n\n\n\n\n0\n2018\n367\nA.J. Ellis\nhttps://www.baseball-reference.com/players/e/e...\n37.0\nSDP\nNL\n0.2\n66.0\n183.0\n...\n.326\n105.0\n52.0\n2.0\n1.0\n3.0\n2.0\n1.0\n2H/7D\nright\n\n\n1\n2018\n174\nAJ Pollock\nhttps://www.baseball-reference.com/players/p/p...\n30.0\nARI\nNL\n2.2\n113.0\n460.0\n...\n.346\n103.0\n200.0\n6.0\n8.0\n1.0\n7.0\n2.0\n*8/H\nright\n\n\n2\n2018\n287\nAaron Altherr\nhttps://www.baseball-reference.com/players/a/a...\n27.0\nPHI\nNL\n-0.9\n105.0\n285.0\n...\n.285\n66.0\n81.0\n13.0\n4.0\n0.0\n2.0\n0.0\n9H8/7\nright\n\n\n3\n2018\n88\nAaron Hicks\nhttps://www.baseball-reference.com/players/h/h...\n28.0\nNYY\nAL\n4.3\n137.0\n581.0\n...\n.366\n128.0\n224.0\n1.0\n3.0\n2.0\n6.0\n1.0\n*8/HD\nleft\n\n\n4\n2018\n145\nAaron Judge\nhttps://www.baseball-reference.com/players/j/j...\n26.0\nNYY\nAL\n6.0\n112.0\n498.0\n...\n.396\n152.0\n218.0\n10.0\n4.0\n0.0\n5.0\n3.0\n9D/H8\nright\n\n\n\n\n5 rows × 36 columns\n\n\n\nThis next set of functions from the package are for scraping and organizing the salary data into a nice dataset.\nThis first one is for creating headers, allowing you to access the data from over 1,000 individaul player pages, as that is the only way to access the salary data.\n\nfrom bbanalysis.gathering_salaries import create_http_headers\n\ncreate_http_headers()\n\n{'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n 'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n 'Accept-Language': 'en-US,en;q=0.5',\n 'Accept-Encoding': 'gzip, deflate',\n 'Connection': 'keep-alive',\n 'Upgrade-Insecure-Requests': '1'}\n\n\nThis next function is to parse the salary data from the players’ pages and scrape it.\n\nfrom bs4 import BeautifulSoup\nfrom bbanalysis.gathering_salaries import parse_salary_table_from_soup\n\nhtml = \"\"\"\n&lt;html&gt;\n&lt;body&gt;\n&lt;table id=\"br-salaries\"&gt;\n    &lt;tr&gt;\n        &lt;th&gt;Year&lt;/th&gt;\n        &lt;th&gt;Salary&lt;/th&gt;\n    &lt;/tr&gt;\n    &lt;tr&gt;\n        &lt;td&gt;2021&lt;/td&gt;\n        &lt;td&gt;$5,000,000&lt;/td&gt;\n    &lt;/tr&gt;\n    &lt;tr&gt;\n        &lt;td&gt;2022&lt;/td&gt;\n        &lt;td&gt;$7,500,000&lt;/td&gt;\n    &lt;/tr&gt;\n&lt;/table&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n\"\"\"\n\nsoup = BeautifulSoup(html, \"html.parser\")\n\nresult = parse_salary_table_from_soup(soup)\nprint(result)\n\n{2021: 5000000, 2022: 7500000}\n\n\nAt this point, you should now have scraped all the statistics data and have the setup for scraping the salary data. These following functions futher prepare and execute the scraping of the data from the actual player pages.\n\n# from bbanalysis.gathering_salaries import scrape_salary_from_url# \n\nThis function uses asyncio to actually scrape the data fromt he site, getting the information needed for the parse function to get the salaries from.\n\nimport pandas as pd\nimport json\nfrom bbanalysis.gathering_salaries import extract_unique_links \n\ntest_csv_path = \"test_players.csv\"\ntest_data = pd.DataFrame({\n    \"Player\": [\"Francisco Lindor\"],\n    \"Player_Link\": [\"https://www.baseball-reference.com/players/l/lindofr01.shtml\"]\n})\ntest_data.to_csv(test_csv_path, index=False)\n\noutput_json_path = \"test_players.json\"\n\nextract_unique_links(test_csv_path, output_json_path)\n\nwith open(output_json_path) as f:\n    data = json.load(f)\n\nprint(json.dumps(data, indent=2))\n\nExtracted 1 unique links and saved to test_players.json\n[\n  {\n    \"id\": 1,\n    \"url\": \"https://www.baseball-reference.com/players/l/lindofr01.shtml\",\n    \"player\": \"Francisco Lindor\"\n  }\n]\n\n\nThis function is important becuase what it does is allow us to organize all the unique player links in one place. Many of the players in the data show up multiple times becuase they played more than one season over the six-year span, so this filters out repeat links.\n\nimport json\nimport cloudscraper\nfrom bbanalysis.gathering_salaries import scrape_with_cloudscraper\n\nscraper = cloudscraper.create_scraper()\nurl = \"https://www.baseball-reference.com/players/l/lindofr01.shtml\"\n\nresult = scrape_with_cloudscraper(url, scraper)\n\n# Transform to required format\nformatted_data = {\n    \"id\": 1,\n    \"player\": \"Francisco Lindor\",\n    \"salaries\": result  # Already in the right format!\n}\n\n# Save as JSON\nwith open('lindor_data.json', 'w', encoding='utf-8') as f:\n    json.dump(formatted_data, f, indent=2)\n\nScraping https://www.baseball-reference.com/players/l/lindofr01.shtml\n\n\nNow with the scrape_salary_from_url function, you may already be able to scrape the salary data. However, due to rate limits it might be really difficult to scrape the data, and you might get errors. Using cloudscraper allows a user to implement their scraper while still maintaining speed and efficiency. Thus the scrape_with_cloudscraper function prepares us to use a cloudscraper.\nNext you will run this funciton:\n\n# If we were to run this, it would take an hour. This function below loops scrape_with_cloudscraper for all links. \n\n# from bbanalysis.gathering_salaries import churn_with_cloudscraper\n# churn_with_cloudscraper()\n\nThis function implements the cloudscraper by creating one, then loops through the unique links dataset and scrapes all the salary data from 2018-2025 using scrape_with_cloudscraper. It then puts all the data into a .json file that stores the salary data. Once this finishes,you now have all the salary data from 2018-2025!\nNow you just need to convert and organize the salary data properly to combine with the other statistical data into one big dataset. This function will organize it as necessary:\n\nfrom bbanalysis.gathering_salaries import salaries_json_to_csv\nsalaries_json_to_csv(\"lindor_data.json\", \"lindor_data.csv\")\n\nSaved long-format salaries to lindor_data.csv\n\n\nNow we’ll combine both the datasets using this function:\n\nimport pandas as pd\nfrom bbanalysis.analysis import load_and_merge_data\n\nstats_test = pd.DataFrame({\n    \"Player\": [\"Mike Trout\", \"Aaron Judge\"],\n    \"Year\": [2021, 2021],\n    \"HR\": [45, 39],\n    \"RBI\": [104, 98]\n})\nstats_csv_path = \"test_stats.csv\"\nstats_test.to_csv(stats_csv_path, index=False)\n\nsalaries_test = pd.DataFrame({\n    \"player\": [\"Mike Trout\", \"Aaron Judge\"],\n    \"year\": [2021, 2021],\n    \"salary\": [5000000, 3000000]\n})\nsalaries_csv_path = \"test_salaries.csv\"\nsalaries_test.to_csv(salaries_csv_path, index=False)\n\nmerged_df = load_and_merge_data(stats_csv_path, salaries_csv_path, \"test_merged.csv\")\n\nprint(merged_df)\n\nLoading and merging data...\nMerged data saved to test_merged.csv\n        player  year  hr  rbi   salary\n0   Mike Trout  2021  45  104  5000000\n1  Aaron Judge  2021  39   98  3000000\n\n\nAnd now we’re ready to do our analysis!\nThe first thing we will do is filter out players who ahve less than five seasons in the dataset, because we want to compare how salary affects play and it is hard to make significant findings otherwise.\n\nimport pandas as pd\nfrom bbanalysis.analysis import filter_players_with_multiple_seasons\n\ntest_data = pd.DataFrame({\n    \"player\": [\"A\", \"A\", \"A\", \"B\", \"B\", \"C\", \"C\", \"C\", \"C\", \"C\"],\n    \"year\": [2018, 2019, 2020, 2019, 2020, 2016, 2017, 2018, 2019, 2020],\n    \"HR\": [10, 12, 15, 5, 6, 20, 22, 25, 18, 19]\n})\n\nfiltered_df = filter_players_with_multiple_seasons(test_data, min_seasons=3)\n\nprint(filtered_df)\n\nKept 2 players with at least 3 seasons.\n  player  year  HR\n0      A  2018  10\n1      A  2019  12\n2      A  2020  15\n5      C  2016  20\n6      C  2017  22\n7      C  2018  25\n8      C  2019  18\n9      C  2020  19\n\n\nThis function filters these players out. Next we will create indicators that mark when a player signs a big contract, leading to a large boost in pay. We will define an increase in $5,000,000 in salary as representative of this.\n\nimport pandas as pd\nimport numpy as np\nfrom bbanalysis.analysis import create_contract_indicators\n\ntest_data = pd.DataFrame({\n    \"player\": [\"A\", \"A\", \"A\", \"B\", \"B\", \"C\", \"C\", \"C\"],\n    \"year\": [2018, 2019, 2020, 2019, 2020, 2018, 2019, 2020],\n    \"salary\": [1_000_000, 1_200_000, 2_500_000, 500_000, 700_000, 2_000_000, 2_100_000, 2_300_000]\n})\n\ndf_with_contracts = create_contract_indicators(test_data, pct_threshold=0.5, abs_threshold=1_000_000)\n\nprint(df_with_contracts)\n\nCreating contract indicators...\nFound 1 big contract events.\nColumns before groupby: ['player', 'year', 'salary', 'salary_change', 'pct_salary_change', 'big_contract_year']\nDataFrame shape before groupby: (8, 6)\nNumber of players: 3\nColumns after groupby: ['player', 'year', 'salary', 'salary_change', 'pct_salary_change', 'big_contract_year', 'years_from_contract']\nDataFrame shape after groupby: (8, 7)\n'years_from_contract' in columns: True\n  player  year   salary  salary_change  pct_salary_change  big_contract_year  \\\n0      A  2018  1000000            NaN                NaN              False   \n1      A  2019  1200000       200000.0           0.200000              False   \n2      A  2020  2500000      1300000.0           1.083333               True   \n3      B  2019   500000            NaN                NaN              False   \n4      B  2020   700000       200000.0           0.400000              False   \n5      C  2018  2000000            NaN                NaN              False   \n6      C  2019  2100000       100000.0           0.050000              False   \n7      C  2020  2300000       200000.0           0.095238              False   \n\n   years_from_contract  post_contract  \n0                 -2.0            0.0  \n1                 -1.0            0.0  \n2                  0.0            1.0  \n3                  NaN            NaN  \n4                  NaN            NaN  \n5                  NaN            NaN  \n6                  NaN            NaN  \n7                  NaN            NaN  \n\n\nC:\\Users\\Jenna\\OneDrive\\Desktop\\Statistics\\Stat 386\\Final_Project\\src\\bbanalysis\\analysis.py:135: FutureWarning:\n\nDataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n\n\n\nNow that we have this created, we can effectively compare statistical performance with before and after a large contract signing. One way to effectively do this is to run mixed effects models. We have a function for this:\n\nimport pandas as pd\nimport numpy as np\nfrom bbanalysis.analysis import run_mixed_effects_models\n\ntest_data = pd.DataFrame({\n    \"player\": [\"A\", \"A\", \"A\", \"B\", \"B\", \"B\", \"C\", \"C\", \"C\"],\n    \"year\": [2018, 2019, 2020, 2018, 2019, 2020, 2018, 2019, 2020],\n    \"salary\": [1_000_000, 1_200_000, 2_500_000, 500_000, 700_000, 700_000, 2_000_000, 2_100_000, 2_300_000],\n    \"ops\": [0.800, 0.850, 0.900, 0.700, 0.720, 0.710, 0.750, 0.760, 0.770],\n    \"war\": [5, 6, 7, 2, 3, 3, 4, 4, 5],\n    \"years_from_contract\": [-1, 0, 1, np.nan, np.nan, np.nan, -1, 0, 1],\n    \"post_contract\": [0, 1, 1, np.nan, np.nan, np.nan, 0, 1, 1],\n    \"age\": [24, 25, 26, 22, 23, 24, 28, 29, 30]\n})\n\nresults = run_mixed_effects_models(test_data, window_years=1)\n\nprint(\"\\nModel 1 summary:\")\nif 'model1' in results:\n    print(results['model1'].summary())\n\nprint(\"\\nModel 2 summary:\")\nif 'model2' in results:\n    print(results['model2'].summary())\n\nprint(\"\\nRestricted df for Model 2:\")\nprint(results.get('df_model2'))\n\n\nRunning Model 1: Salary → OPS (all players)\n\n\nC:\\Users\\Jenna\\OneDrive\\Desktop\\Statistics\\Stat 386\\Final_Project\\.venv\\Lib\\site-packages\\statsmodels\\regression\\mixed_linear_model.py:1634: UserWarning:\n\nRandom effects covariance is singular\n\nC:\\Users\\Jenna\\OneDrive\\Desktop\\Statistics\\Stat 386\\Final_Project\\.venv\\Lib\\site-packages\\statsmodels\\regression\\mixed_linear_model.py:1634: UserWarning:\n\nRandom effects covariance is singular\n\nC:\\Users\\Jenna\\OneDrive\\Desktop\\Statistics\\Stat 386\\Final_Project\\.venv\\Lib\\site-packages\\statsmodels\\regression\\mixed_linear_model.py:1634: UserWarning:\n\nRandom effects covariance is singular\n\nC:\\Users\\Jenna\\OneDrive\\Desktop\\Statistics\\Stat 386\\Final_Project\\.venv\\Lib\\site-packages\\statsmodels\\regression\\mixed_linear_model.py:1634: UserWarning:\n\nRandom effects covariance is singular\n\nC:\\Users\\Jenna\\OneDrive\\Desktop\\Statistics\\Stat 386\\Final_Project\\.venv\\Lib\\site-packages\\statsmodels\\regression\\mixed_linear_model.py:2237: ConvergenceWarning:\n\nThe MLE may be on the boundary of the parameter space.\n\nC:\\Users\\Jenna\\OneDrive\\Desktop\\Statistics\\Stat 386\\Final_Project\\.venv\\Lib\\site-packages\\statsmodels\\regression\\mixed_linear_model.py:2261: ConvergenceWarning:\n\nThe Hessian matrix at the estimated parameter values is not positive definite.\n\n\n\n        Mixed Linear Model Regression Results\n=====================================================\nModel:            MixedLM Dependent Variable: ops    \nNo. Observations: 9       Method:             ML     \nNo. Groups:       3       Scale:              0.0002 \nMin. group size:  3       Log-Likelihood:     26.3591\nMax. group size:  3       Converged:          Yes    \nMean group size:  3.0                                \n-----------------------------------------------------\n          Coef.  Std.Err.   z    P&gt;|z|  [0.025 0.975]\n-----------------------------------------------------\nIntercept 11.122   11.416  0.974 0.330 -11.253 33.497\nsalary    -0.000    0.000 -2.246 0.025  -0.000 -0.000\nwar        0.045    0.004 12.693 0.000   0.038  0.052\nyear      -0.005    0.006 -0.922 0.356  -0.016  0.006\nGroup Var  0.000                                     \n=====================================================\n\n\nRunning Model 2: Pre vs Post contract performance\nUsing 6 observations from 2 players.\n            Mixed Linear Model Regression Results\n=============================================================\nModel:                MixedLM   Dependent Variable:   ops    \nNo. Observations:     6         Method:               ML     \nNo. Groups:           2         Scale:                0.0003 \nMin. group size:      3         Log-Likelihood:       16.0031\nMax. group size:      3         Converged:            No     \nMean group size:      3.0                                    \n-------------------------------------------------------------\n               Coef.   Std.Err.   z    P&gt;|z|  [0.025   0.975]\n-------------------------------------------------------------\nIntercept     -104.585   33.739 -3.100 0.002 -170.712 -38.458\npost_contract    0.000    0.028  0.000 1.000   -0.055   0.055\nage             -0.022    0.004 -6.194 0.000   -0.030  -0.015\nyear             0.052    0.017  3.138 0.002    0.020   0.085\nGroup Var        0.000                                       \n=============================================================\n\n\nPost-contract effect interpretation:\nCoefficient: 0.0000 | p-value: 1.0000 | 95% CI: [-0.0554, 0.0554]\nNo significant post-contract effect.\n\nModel 1 summary:\n        Mixed Linear Model Regression Results\n=====================================================\nModel:            MixedLM Dependent Variable: ops    \nNo. Observations: 9       Method:             ML     \nNo. Groups:       3       Scale:              0.0002 \nMin. group size:  3       Log-Likelihood:     26.3591\nMax. group size:  3       Converged:          Yes    \nMean group size:  3.0                                \n-----------------------------------------------------\n          Coef.  Std.Err.   z    P&gt;|z|  [0.025 0.975]\n-----------------------------------------------------\nIntercept 11.122   11.416  0.974 0.330 -11.253 33.497\nsalary    -0.000    0.000 -2.246 0.025  -0.000 -0.000\nwar        0.045    0.004 12.693 0.000   0.038  0.052\nyear      -0.005    0.006 -0.922 0.356  -0.016  0.006\nGroup Var  0.000                                     \n=====================================================\n\n\nModel 2 summary:\n            Mixed Linear Model Regression Results\n=============================================================\nModel:                MixedLM   Dependent Variable:   ops    \nNo. Observations:     6         Method:               ML     \nNo. Groups:           2         Scale:                0.0003 \nMin. group size:      3         Log-Likelihood:       16.0031\nMax. group size:      3         Converged:            No     \nMean group size:      3.0                                    \n-------------------------------------------------------------\n               Coef.   Std.Err.   z    P&gt;|z|  [0.025   0.975]\n-------------------------------------------------------------\nIntercept     -104.585   33.739 -3.100 0.002 -170.712 -38.458\npost_contract    0.000    0.028  0.000 1.000   -0.055   0.055\nage             -0.022    0.004 -6.194 0.000   -0.030  -0.015\nyear             0.052    0.017  3.138 0.002    0.020   0.085\nGroup Var        0.000                                       \n=============================================================\n\n\nRestricted df for Model 2:\n  player  year   salary   ops  war  years_from_contract  post_contract  age\n0      A  2018  1000000  0.80    5                 -1.0            0.0   24\n1      A  2019  1200000  0.85    6                  0.0            1.0   25\n2      A  2020  2500000  0.90    7                  1.0            1.0   26\n6      C  2018  2000000  0.75    4                 -1.0            0.0   28\n7      C  2019  2100000  0.76    4                  0.0            1.0   29\n8      C  2020  2300000  0.77    5                  1.0            1.0   30\n\n\nC:\\Users\\Jenna\\OneDrive\\Desktop\\Statistics\\Stat 386\\Final_Project\\.venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning:\n\nMaximum Likelihood optimization failed to converge. Check mle_retvals\n\nC:\\Users\\Jenna\\OneDrive\\Desktop\\Statistics\\Stat 386\\Final_Project\\.venv\\Lib\\site-packages\\statsmodels\\regression\\mixed_linear_model.py:2200: ConvergenceWarning:\n\nRetrying MixedLM optimization with lbfgs\n\nC:\\Users\\Jenna\\OneDrive\\Desktop\\Statistics\\Stat 386\\Final_Project\\.venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning:\n\nMaximum Likelihood optimization failed to converge. Check mle_retvals\n\nC:\\Users\\Jenna\\OneDrive\\Desktop\\Statistics\\Stat 386\\Final_Project\\.venv\\Lib\\site-packages\\statsmodels\\regression\\mixed_linear_model.py:2200: ConvergenceWarning:\n\nRetrying MixedLM optimization with cg\n\nC:\\Users\\Jenna\\OneDrive\\Desktop\\Statistics\\Stat 386\\Final_Project\\.venv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning:\n\nMaximum Likelihood optimization failed to converge. Check mle_retvals\n\nC:\\Users\\Jenna\\OneDrive\\Desktop\\Statistics\\Stat 386\\Final_Project\\.venv\\Lib\\site-packages\\statsmodels\\regression\\mixed_linear_model.py:2206: ConvergenceWarning:\n\nMixedLM optimization failed, trying a different optimizer may help.\n\nC:\\Users\\Jenna\\OneDrive\\Desktop\\Statistics\\Stat 386\\Final_Project\\.venv\\Lib\\site-packages\\statsmodels\\regression\\mixed_linear_model.py:2218: ConvergenceWarning:\n\nGradient optimization failed, |grad| = 1.263158\n\nC:\\Users\\Jenna\\OneDrive\\Desktop\\Statistics\\Stat 386\\Final_Project\\.venv\\Lib\\site-packages\\statsmodels\\regression\\mixed_linear_model.py:2237: ConvergenceWarning:\n\nThe MLE may be on the boundary of the parameter space.\n\nC:\\Users\\Jenna\\OneDrive\\Desktop\\Statistics\\Stat 386\\Final_Project\\.venv\\Lib\\site-packages\\statsmodels\\regression\\mixed_linear_model.py:2261: ConvergenceWarning:\n\nThe Hessian matrix at the estimated parameter values is not positive definite.\n\n\n\nFrom these mixed effects models we can glean valuable information, like does performance increase or decrease with salary increase or decrease over time, and whether a steep increase in salary can have a big impact on a player’s performance.\nThe next step would be visualizing the data through using this function:\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom bbanalysis.analysis import generate_visualizations\n\ntest_data = pd.DataFrame({\n    \"player\": [\"A\", \"A\", \"A\", \"B\", \"B\", \"B\", \"C\", \"C\", \"C\"],\n    \"year\": [2018, 2019, 2020, 2018, 2019, 2020, 2018, 2019, 2020],\n    \"ops\": [0.800, 0.850, 0.900, 0.700, 0.720, 0.710, 0.750, 0.760, 0.770],\n    \"war\": [5, 6, 7, 2, 3, 3, 4, 4, 5],\n    \"years_from_contract\": [-1, 0, 1, np.nan, np.nan, np.nan, -1, 0, 1],\n    \"post_contract\": [0, 1, 1, np.nan, np.nan, np.nan, 0, 1, 1]\n})\n\noutput_dir = \"test_plots\"\nif os.path.exists(output_dir):\n    import shutil\n    shutil.rmtree(output_dir)\n\ngenerate_visualizations(test_data, output_dir=output_dir)\n\nprint(\"Files in output directory:\", os.listdir(output_dir))\n\n\nGenerating visualizations → saved to 'test_plots/'\nAll visualizations saved.\nFiles in output directory: ['contract_boxplots.png', 'contract_trajectory.png']"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Stat 386 Final Project",
    "section": "",
    "text": "MLB Baseball Performance vs Salary\nBy: Isaac Miller and Jenna Worthen\nFor our final project, we decided to focus on the effect of salaries on a baseball player’s productivity. One thing that seems to be a common occurrence among baseball players (and the sporting industry as a whole) is that as soon as they sign a big contract of guaranteed money, their production on the field seems to regress. No example of this is more apparent than that of Anthony Rendon, who after almost winning MVP and leading his team to a world series title in 2019, immediately seemed to regress after signing a massive contract with the Los Angeles Angels. This, along with several other notable examples, prompted us to ask the question: Does a player’s salary negatively impact their play?\n\n\n\nAnthony Rendon by Larry Brown Sports\n\n\nWe will built a python package that will enable users replicate how we scraped and analyzed baseball data from baseball-reference.com. View the links below to see our documentation and results!\nStreamlit Interactive App here.\nDocumentation here.\nTutorial here.\nReview the technical report.\nHard Skills we demonstrate in Python: webscraping (streamlit and BeautifulSoup), modeling with multiple linear regression, data cleaning and wrangling, data visualization"
  },
  {
    "objectID": "Documentation.html",
    "href": "Documentation.html",
    "title": "Documentation",
    "section": "",
    "text": "This goes through the process of each function for each step of our process of collecting the data, organizing it into a coherent dataset, and performing analysis.\nThe first part starts with the collection of baseball hitting statistics from 2018 - 2025 to get a large sample of current data to work with. Collecting salaries was more complicated so we will go over this after. All the data was collected through the site baseball-reference.com.\nThis first chunk will show the initial setup for the data collection:\n\nimport requests\nimport re\nfrom bs4 import BeautifulSoup\nimport pandas as pd\nimport time\n\nURLS = [\n    'https://www.baseball-reference.com/leagues/majors/2018-standard-batting.shtml',\n    'https://www.baseball-reference.com/leagues/majors/2019-standard-batting.shtml',\n    'https://www.baseball-reference.com/leagues/majors/2020-standard-batting.shtml',\n    'https://www.baseball-reference.com/leagues/majors/2021-standard-batting.shtml',\n    'https://www.baseball-reference.com/leagues/majors/2022-standard-batting.shtml',\n    'https://www.baseball-reference.com/leagues/majors/2023-standard-batting.shtml',\n    'https://www.baseball-reference.com/leagues/majors/2024-standard-batting.shtml',\n    'https://www.baseball-reference.com/leagues/majors/2025-standard-batting.shtml',\n]\n\nHEADERS = {\n    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'\n}\n\nCOLUMNS = [\n    'Rk','Player','Age','Team','Lg','WAR','G','PA','AB','R','H','2B','3B','HR','RBI',\n    'SB','CS','BB','SO','BA','OBP','SLG','OPS','OPS+','rOBA','Rbat+','TB','GIDP',\n    'HBP','SH','SF','IBB','Pos','Awards'\n]\n\nThis chunk sets up where the data is going to be scraped from and which columns to use.\nThis second chunk is the function to actually scrape all the statistics data from those pages. It identifies where to scrape from, how many rows to scrape, and loops through the hitting dataset from each year from 2018 - 2025. It creates the dataframe for all the statistics.\n\ndef scrape_batting_data(urls):\n    all_data = []\n\n    for url in urls:\n        year = int(re.search(r'/(\\d{4})', url).group(1))\n        print(f\"\\nScraping {year}...\")\n\n        r = requests.get(url, headers=HEADERS, timeout=15)\n        r.raise_for_status()\n        soup = BeautifulSoup(r.text, 'html.parser')\n\n        div = soup.find('div', id='switcher_players_standard_batting')\n        if not div:\n            print(\"  Switcher div not found\")\n            continue\n\n        table = div.find('table', id='players_standard_batting')\n        if not table:\n            print(\"  Table not found\")\n            continue\n\n        tbody = table.find('tbody')\n        if not tbody:\n            print(\"  Tbody not found\")\n            continue\n\n        seen = set()\n\n        for row in tbody.find_all('tr'):\n            if row.get('class') and 'thead' in row.get('class'):\n                continue\n\n            cells = row.find_all(['th', 'td'])\n            if len(cells) &lt; 25:\n                continue\n\n            player_cell = cells[1]\n            player_name = player_cell.get_text(strip=True)\n            team = cells[3].get_text(strip=True)\n\n            if player_name in seen and team != 'TOT':\n                continue\n\n            if team == 'TOT' or player_name not in seen:\n                seen.add(player_name)\n\n                row_dict = {'Year': year}\n\n                pos_map = {\n                    0: 'Rk', 1: 'Player', 2: 'Age', 3: 'Team', 4: 'Lg',\n                    5: 'WAR', 6: 'G', 7: 'PA', 8: 'AB', 9: 'R', 10: 'H',\n                    11: '2B', 12: '3B', 13: 'HR', 14: 'RBI', 15: 'SB',\n                    16: 'CS', 17: 'BB', 18: 'SO', 19: 'BA', 20: 'OBP',\n                    21: 'SLG', 22: 'OPS', 23: 'OPS+', 24: 'rOBA',\n                    25: 'Rbat+', 26: 'TB', 27: 'GIDP', 28: 'HBP',\n                    29: 'SH', 30: 'SF', 31: 'IBB', 32: 'Pos', 33: 'Awards'\n                }\n\n                for idx, cell in enumerate(cells):\n                    col_name = pos_map.get(idx)\n                    if not col_name:\n                        continue\n\n                    if col_name == 'Player':\n                        row_dict['Player'] = player_name\n                        a = cell.find('a')\n                        if a:\n                            row_dict['Player_Link'] = (\n                                'https://www.baseball-reference.com' + a['href']\n                            )\n                    else:\n                        row_dict[col_name] = cell.get_text(strip=True)\n\n                for col in COLUMNS:\n                    row_dict.setdefault(col, '')\n\n                all_data.append(row_dict)\n\n        print(f\"  {len(seen)} players scraped for {year}\")\n        time.sleep(1.2)\n\n    return all_data\n\nThis third function cleans the data and organizes it into a coherent dataframe. The function within it, get_batting_hand(), identifies whether each player is left handed, right handed, or bats with both hands, as we decided this would also be useful information in determining the overall value of a hitter.\n\ndef clean_batting_data(df):\n    numeric_cols = [\n        'Age','WAR','G','PA','AB','R','H','2B','3B','HR','RBI','SB','CS',\n        'BB','SO','OPS+','TB','GIDP','HBP','SH','SF','IBB','Rbat+'\n    ]\n\n    for col in numeric_cols:\n        df[col] = pd.to_numeric(df[col], errors='coerce')\n\n    df = df[~df['Player'].str.contains('MLB Average', case=False, na=False)]\n    df = df[df['PA'] &gt;= 100]\n\n    def get_batting_hand(name):\n        if name.endswith('*'):\n            return 'both'\n        elif name.endswith('#'):\n            return 'left'\n        elif name.endswith('?'):\n            return 'unknown'\n        return 'right'\n\n    df['batting_hand'] = df['Player'].apply(get_batting_hand)\n    df['Player'] = df['Player'].str.rstrip('*#?')\n\n    df = df.drop(columns=['Awards'])\n    df = df.sort_values(['Player', 'Year'])\n    df = df.drop_duplicates(subset=['Player', 'Year'], keep='first')\n\n    player_counts = df['Player'].value_counts()\n    players_2plus = player_counts[player_counts &gt;= 3].index\n    df = df[df['Player'].isin(players_2plus)]\n\n    return df.reset_index(drop=True)\n\nThis main function actually implements the previous functions, scraping all the statistics according to how we wanted, to create a dataset of each mlb hitter from 2018 - 2025, filtered to players with over 100 plate appearances in at least one of the seasons.\n\ndef main():\n    all_data = scrape_batting_data(URLS)\n\n    df = pd.DataFrame(\n        all_data,\n        columns=['Year'] + COLUMNS + ['Player_Link']\n    )\n\n    mlb = clean_batting_data(df)\n\n    mlb.to_csv('MLB_2018_2025_Cleaned.csv', index=False)\n    print(\"\\nSaved: MLB_2018_2025_Cleaned.csv\")\n\n\n# ==========================\n# ENTRY POINT\n# ==========================\n\nif __name__ == \"__main__\":\n    main()\n\nNow we will move on to the next part of the data collection, which is gathering the salary data. This was more complicated to collect, because there is no dataset that has each player’s salary data in one place. We had to build a scraper that iterated through the unique page of each player in the dataset within baseball-reference and scraped their salaries from 2018 - 2025. The first dataset had included the links to each of these players’ pages, so we utilized this to create a json file of unique player links for the scraper to iterate through, so that no players’ page would be accessed more than once. Each code chunk will be explained below.\n\ndef create_http_headers() -&gt; dict[str, str]:\n    return {\n        'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n        'Accept-Language': 'en-US,en;q=0.5',\n        'Accept-Encoding': 'gzip, deflate',\n        'Connection': 'keep-alive',\n        'Upgrade-Insecure-Requests': '1',\n    }\n\nThis first function creates the headers that allows us to access the data and browser without being blocked.\n\ndef parse_salary_table_from_soup(soup: BeautifulSoup) -&gt; dict[int, int]:\n    \n    salary_dict = {}\n   \n    # First try to find the table normally\n    salary_table = soup.find('table', {'id': 'br-salaries'})\n   \n    # If not found, look for it in HTML comments (common pattern for baseball-reference)\n    if not salary_table:\n        comments = soup.find_all(string=lambda text: isinstance(text, Comment))\n        for comment in comments:\n            if 'id=\"br-salaries\"' in comment:\n                comment_soup = BeautifulSoup(comment, 'html.parser')\n                salary_table = comment_soup.find('table', {'id': 'br-salaries'})\n                if salary_table:\n                    break\n   \n    if not salary_table:\n        return salary_dict\n   \n    rows = salary_table.find_all('tr')\n    if not rows:\n        return salary_dict\n   \n    header_row = rows[0]\n    headers = [th.get_text().strip() for th in header_row.find_all(['th', 'td'])]\n   \n    try:\n        year_col_idx = headers.index('Year')\n        salary_col_idx = headers.index('Salary')\n    except ValueError:\n        return salary_dict\n   \n    for row in rows[1:]:\n        cells = row.find_all(['td', 'th'])\n        if len(cells) &lt;= max(year_col_idx, salary_col_idx):\n            continue\n           \n        year_text = cells[year_col_idx].get_text().strip()\n        salary_text = cells[salary_col_idx].get_text().strip()\n       \n        if year_text.isdigit() and len(year_text) == 4:\n            try:\n                year = int(year_text)\n                if 2018 &lt;= year &lt;= 2025:\n                    if salary_text and salary_text.startswith('$'):\n                        salary_clean = salary_text.replace(\"$\", \"\").replace(\",\", \"\").strip()\n                        if salary_clean:\n                            try:\n                                salary = int(salary_clean)\n                                salary_dict[year] = salary\n                            except ValueError:\n                                pass\n            except ValueError:\n                continue\n   \n    return salary_dict\n\nThis second function is the one that finds and parses the salary data in each player’s page. It identifies where it is, finds the salaries from 2018-2025, and converts the data frmo string to integer form. One difficulty is that many, if not all, of the players’ salary data was within comments in the source code of their individual pages, so we had to account for this in our scraper.\n\n  async def scrape_salary_from_url(url: str, session: aiohttp.ClientSession) -&gt; dict[int, int]:\n    print(f\"Starting to scrape {url}.\")\n   \n    try:\n        async with session.get(url, timeout=aiohttp.ClientTimeout(total=30)) as response:\n            if response.status != 200:\n                print(f\"Failed to fetch {url}: HTTP {response.status}\")\n                return {}\n           \n            html = await response.text()\n            soup = BeautifulSoup(html, 'html.parser')\n            salary_dict = parse_salary_table_from_soup(soup)\n           \n            print(f\"Done scraping {url}. Found {len(salary_dict)} salary entries.\")\n            return salary_dict\n           \n    except asyncio.TimeoutError:\n        print(f\"Timeout while scraping {url}\")\n        return {}\n    except aiohttp.ClientError as e:\n        print(f\"HTTP error while scraping {url}: {e}\")\n        return {}\n    except Exception as e:\n        print(f\"Unexpected error while scraping {url}: {e}\")\n        return {}\n\nThis function downloads each player’s page asynchonously and extracts the salary data.\n\ndef extract_unique_links(csv_path: str, output_json_path: str) -&gt; None:\n    \"\"\"Extract unique player links from CSV and save as JSON\"\"\"\n    df = pd.read_csv(csv_path)\n   \n    url_to_player = df.dropna(subset=['Player_Link']).drop_duplicates(subset=['Player_Link']).set_index('Player_Link')['Player'].to_dict()\n    unique_urls = df['Player_Link'].dropna().unique().tolist()\n    links_with_ids = [{\"id\": i + 1, \"url\": url, \"player\": url_to_player[url]} for i, url in enumerate(unique_urls)]\n   \n    with open(output_json_path, 'w') as f:\n        json.dump(links_with_ids, f, indent=2)\n\nThis function extracts the links out of the dataset of player links, to create a list of each unique players’ page links (each player’s link appearing once). This allows our function to easily loop through without accessing players’ pages multiple times, as many players played multiple seasons over the 2018 - 2025 period.\n\ndef scrape_with_cloudscraper(url: str, scraper) -&gt; dict[int, int]:\n    print(f\"Scraping {url}\")\n    try:\n        html = scraper.get(url, timeout=30).text\n        soup = BeautifulSoup(html, 'html.parser')\n        return parse_salary_table_from_soup(soup)\n    except Exception as e:\n        print(f\"Failed {url}: {e}\")\n        return {}\n\nThis function utilizes cloudscraper to bypass Cloudflare in baseball-reference, ebcause cloudflare was blocking any attempts to scrape data from the pages otherwise.\n\ndef churn_with_cloudscraper():\n    scraper = cloudscraper.create_scraper(\n        browser={'browser': 'chrome', 'platform': 'windows', 'mobile': False},\n        delay=10\n    )\n\n    with open(\"unique_links.json\", \"r\") as f:\n        links = json.load(f)\n\n    try:\n        with open(\"salaries.json\", \"r\") as f:\n            existing = json.load(f)\n    except:\n        existing = []\n\n    existing_ids = {x['id'] for x in existing}\n    remaining = [l for l in links if l['id'] not in existing_ids]\n\n    results = {e['id']: e for e in existing}\n\n    for link in remaining:\n        salary_data = scrape_with_cloudscraper(link['url'], scraper)\n        results[link['id']] = {\n            \"id\": link['id'],\n            \"player\": link['player'],\n            \"salaries\": salary_data\n        }\n\n        \n        with open(\"salaries.json\", \"w\") as f:\n            json.dump(sorted(results.values(), key=lambda x: x['id']), f, indent=2)\n\n        print(f\"Success: Saved {link['player']} → {len(salary_data)} years\")\n        time.sleep(4)  \n\n    print(\"All done!\")\n\nThis function organizes everything together to scrape the data, utilizing the cloudscraper function, laoding all the urls, saving progress to be able to pause and resume later, iterates over each link, limits rates, and outputs the data to salaries.json.\nSo now we have all the data scraped that we need. We just need to organize it into a coherent dataset so we can perform analysis. Since we used json files to store the salary data, we need to convert it to csv so we can combine it with the hitting statistics data.\n\nwith open(\"salaries.json\") as f:\n    data = json.load(f)\n\ndf = pd.json_normalize(data)\n\nlong_df = (\n    df\n    .melt(\n        id_vars=[\"id\", \"player\"],           # columns to keep\n        var_name=\"year\",\n        value_name=\"salary\"\n    )\n)\n\n# # Extract year number from 'salaries.2018'\nlong_df[\"year\"] = long_df[\"year\"].str.replace(\"salaries.\", \"\", regex=False).astype(int)\n\nlong_df.to_csv(\"salaries.csv\", index=False)\n\nThis code converts the salary.json file into a csv file, and melts to organize the data to easily combine with the other salary data.\n\ndef load_and_merge_data(stats_path='MLB_2018_2025_Cleaned.csv',\n                        salary_path='salaries.csv',\n                        output_merged_path='MLB_2018_2025_Full.csv'):\n    \"\"\"\n    Load player stats and salary data, merge them, and save the merged dataset.\n    \n    Parameters:\n        stats_path (str): Path to the cleaned player stats CSV.\n        salary_path (str): Path to the salaries CSV.\n        output_merged_path (str): Where to save the merged DataFrame.\n    \n    Returns:\n        pd.DataFrame: Merged dataset with salary information.\n    \"\"\"\n    print(\"Loading and merging data...\")\n    df = pd.read_csv(stats_path)\n    salary = pd.read_csv(salary_path)\n    \n    # Standardize column names\n    df.columns = df.columns.str.lower()\n    \n    # Merge on player name and year\n    full = df.merge(salary, on=[\"player\", \"year\"], how=\"left\")\n    \n    # Save merged file for future use\n    full.to_csv(output_merged_path, index=False)\n    print(f\"Merged data saved to {output_merged_path}\")\n    \n    return full\n\nThis function conbines the salary and statsitcs datasets together into one dataset.\n\ndef filter_players_with_multiple_seasons(df, min_seasons=5):\n    \"\"\"\n    Filter to players with at least `min_seasons` seasons (default &gt;4, i.e. 5+).\n    \n    Parameters:\n        df (pd.DataFrame): Input DataFrame with 'player' column.\n        min_seasons (int): Minimum number of seasons required.\n    \n    Returns:\n        pd.DataFrame: Filtered DataFrame.\n    \"\"\"\n    counts = df[\"player\"].value_counts()\n    qualified_players = counts[counts &gt;= min_seasons].index\n    df_filtered = df[df[\"player\"].isin(qualified_players)].copy()\n    print(f\"Kept {len(qualified_players)} players with at least {min_seasons} seasons.\")\n    return df_filtered\n\nThis function takes the dataset and filters out some of the players. MAny players in the dataset didn’t have salareis recorded in baseball-reference, so tehy had to be filtered out, and many others only played one or two seasons during the period, so they were filtered out as well.\n\ndef create_contract_indicators(df_filtered,\n                               pct_threshold=0.5,\n                               abs_threshold=5_000_000):\n    \"\"\"\n    Create indicators for 'big contract' years and years relative to contract.\n    \n    Parameters:\n        df_filtered (pd.DataFrame): DataFrame with salary and player info.\n        pct_threshold (float): Percent salary increase to qualify as big contract.\n        abs_threshold (float): Absolute dollar increase to qualify.\n    \n    Returns:\n        pd.DataFrame: DataFrame with new columns:\n                      - big_contract_year\n                      - years_from_contract\n                      - post_contract\n    \"\"\"\n    print(\"Creating contract indicators...\")\n    df = df_filtered.sort_values(['player', 'year']).copy()\n    \n    # Year-over-year changes\n    df['salary_change'] = df.groupby('player')['salary'].diff()\n    df['pct_salary_change'] = df.groupby('player')['salary'].pct_change()\n    \n    # Flag big contract years\n    df['big_contract_year'] = (\n        (df['pct_salary_change'] &gt; pct_threshold) |\n        (df['salary_change'] &gt; abs_threshold)\n    )\n    \n    print(f\"Found {df['big_contract_year'].sum()} big contract events.\")\n    \n    # Mark years relative to first big contract for each player\n    def mark_years_from_contract(player_df):\n        if player_df['big_contract_year'].any():\n            contract_year = player_df[player_df['big_contract_year']].iloc[0]['year']\n            player_df['years_from_contract'] = player_df['year'] - contract_year\n        else:\n            player_df['years_from_contract'] = np.nan\n        return player_df\n    \n    df = df.groupby('player', group_keys=False).apply(mark_years_from_contract)\n    \n    # Post-contract indicator (0 = pre, 1 = post, NaN = no contract)\n    df['post_contract'] = (df['years_from_contract'] &gt;= 0).astype(float)\n    df.loc[df['years_from_contract'].isna(), 'post_contract'] = np.nan\n    \n    return df\n\nThis function creates big contract indicators. Basically we wanted to identify when a player signed a big contract, to see if his play drastically changed from before to after they signed a contrct. It identifies when a player signed a large contract, defined as at least a 5 million dollar increase in salary, and marks up to two years before and after the signing.\n\ndef run_mixed_effects_models(df_processed, window_years=3):\n    \"\"\"\n    Run the two main mixed-effects models:\n        1. Overall salary → performance\n        2. Pre/Post contract performance change (with controls)\n    \n    Parameters:\n        df_processed (pd.DataFrame): DataFrame after contract indicators.\n        window_years (int): How many years before/after contract to include.\n    \n    Returns:\n        dict: Contains fitted models and restricted dataset for model2.\n    \"\"\"\n    results = {}\n    \n    # Model 1: All players - Does salary predict performance?\n    print(\"\\nRunning Model 1: Salary → OPS (all players)\")\n    df_model1 = df_processed.dropna(subset=['ops', 'salary', 'war', 'year'])\n    try:\n        model1 = smf.mixedlm(\"ops ~ salary + war + year\",\n                            data=df_model1,\n                            groups=df_model1[\"player\"]).fit(reml=False)\n        print(model1.summary())\n        results['model1'] = model1\n    except Exception as e:\n        print(f\"Model 1 failed: {e}\")\n    \n    # Model 2: Pre/Post contract (restricted window)\n    print(\"\\nRunning Model 2: Pre vs Post contract performance\")\n    df_model2 = df_processed[\n        (df_processed['years_from_contract'].notna()) &\n        (df_processed['years_from_contract'].between(-window_years, window_years))\n    ].copy()\n    \n    print(f\"Using {len(df_model2)} observations from {df_model2['player'].nunique()} players.\")\n    \n    # Formula: include age if available\n    if 'age' in df_model2.columns:\n        formula = \"ops ~ post_contract + age + year\"\n    else:\n        formula = \"ops ~ post_contract + year\"\n        print(\"Note: 'age' column missing → excluded from model.\")\n    \n    try:\n        model2 = smf.mixedlm(formula,\n                            data=df_model2,\n                            groups=df_model2[\"player\"]).fit(reml=False)\n        print(model2.summary())\n        \n        # Interpretation\n        coef = model2.params['post_contract']\n        pval = model2.pvalues['post_contract']\n        ci = model2.conf_int().loc['post_contract']\n        \n        print(\"\\nPost-contract effect interpretation:\")\n        print(f\"Coefficient: {coef:.4f} | p-value: {pval:.4f} | 95% CI: [{ci[0]:.4f}, {ci[1]:.4f}]\")\n        if pval &lt; 0.05:\n            print(\"Significant change detected.\" if coef &lt; 0 else \"Significant improvement detected.\")\n        else:\n            print(\"No significant post-contract effect.\")\n        \n        results['model2'] = model2\n        results['df_model2'] = df_model2\n    except Exception as e:\n        print(f\"Model 2 failed: {e}\")\n    \n    return results\n\nThis function creates mixed effects models to visualize salary with hitting statistics comparisons, and for before and after the contract signnig; it also makes comparisons based on age, because if a player signs a contract at a certain age their decline could be more due to age than the contract signing.\n\ndef run_full_analysis(stats_path='MLB_2018_2025_Cleaned.csv',\n                      salary_path='salaries.csv',\n                      min_seasons=5,\n                      output_dir='plots'):\n    \"\"\"\n    Complete end-to-end analysis pipeline.\n    Call this function from other scripts to reproduce the full analysis.\n    \"\"\"\n    print(\"=\"*80)\n    print(\"STARTING MLB BIG CONTRACT PERFORMANCE ANALYSIS\")\n    print(\"=\"*80)\n    \n    # Step 1: Load and merge\n    full_df = load_and_merge_data(stats_path, salary_path)\n    \n    # Step 2: Filter players\n    df_filtered = filter_players_with_multiple_seasons(full_df, min_seasons=min_seasons)\n    \n    # Step 3: Create contract indicators\n    df_processed = create_contract_indicators(df_filtered)\n    \n    # Step 4: Run models\n    results = run_mixed_effects_models(df_processed)\n    \n    # Step 5: Visualizations (if model2 succeeded)\n    if 'df_model2' in results:\n        generate_visualizations(results['df_model2'], output_dir=output_dir)\n    \n    print(\"\\nANALYSIS COMPLETE!\")\n    print(\"=\"*80)\n    \n    return {\n        'full_data': full_df,\n        'processed_data': df_processed,\n        'models': results\n    }\n\n\n# ==============================================================================\n# Example usage when run directly\n# ==============================================================================\nif __name__ == \"__main__\":\n    run_full_analysis()\n\nThis last function incoropates All of the other functions, to run the full analysis, allowing us to effectively analyze and visualize the data regarding MLB hitters and salaries."
  },
  {
    "objectID": "TechnicalReport.html",
    "href": "TechnicalReport.html",
    "title": "Technical Report",
    "section": "",
    "text": "This analysis investigates whether signing large contracts negatively impacts MLB player performance, examining the commonly held belief that financial security leads to decreased motivation and effort. Using data from 300 MLB hitters across the 2018-2025 seasons (1,985 player-seasons), we identified 495 “big contract” events and compared player performance before and after contract signing using OPS and WAR as primary performance metrics.\nKey Findings:\n\nDescriptive statistics show an apparent decline in performance post-contract (ΔOPS = -0.020, ΔWAR = -0.241)\nHowever, mixed effects regression controlling for age and player-specific effects found no significant contract effect (β = 0.011, p = 0.113)\nAge was the only significant predictor of performance decline (β = -0.004, p = 0.010)\nPlayers typically sign major contracts at ages 28-31, coinciding with natural performance decline\n59.3% of players declined post-contract, consistent with normal aging patterns rather than systematic motivational effects\n\nActionable Recommendations:\n\nTeams should not discount player value based on contract status; performance decline is attributable to age, not contract-induced complacency\nFront offices should focus on age and injury risk rather than motivational concerns when evaluating contract extensions\nHigh-profile “failures” like Anthony Rendon appear to be outliers driven by injuries and aging rather than representative of systematic patterns"
  },
  {
    "objectID": "TechnicalReport.html#executive-summary",
    "href": "TechnicalReport.html#executive-summary",
    "title": "Technical Report",
    "section": "",
    "text": "This analysis investigates whether signing large contracts negatively impacts MLB player performance, examining the commonly held belief that financial security leads to decreased motivation and effort. Using data from 300 MLB hitters across the 2018-2025 seasons (1,985 player-seasons), we identified 495 “big contract” events and compared player performance before and after contract signing using OPS and WAR as primary performance metrics.\nKey Findings:\n\nDescriptive statistics show an apparent decline in performance post-contract (ΔOPS = -0.020, ΔWAR = -0.241)\nHowever, mixed effects regression controlling for age and player-specific effects found no significant contract effect (β = 0.011, p = 0.113)\nAge was the only significant predictor of performance decline (β = -0.004, p = 0.010)\nPlayers typically sign major contracts at ages 28-31, coinciding with natural performance decline\n59.3% of players declined post-contract, consistent with normal aging patterns rather than systematic motivational effects\n\nActionable Recommendations:\n\nTeams should not discount player value based on contract status; performance decline is attributable to age, not contract-induced complacency\nFront offices should focus on age and injury risk rather than motivational concerns when evaluating contract extensions\nHigh-profile “failures” like Anthony Rendon appear to be outliers driven by injuries and aging rather than representative of systematic patterns"
  },
  {
    "objectID": "TechnicalReport.html#project-context",
    "href": "TechnicalReport.html#project-context",
    "title": "Technical Report",
    "section": "Project Context",
    "text": "Project Context\nMotivation:\nProfessional sports discourse frequently suggests that athletes underperform after signing lucrative contracts, with financial security allegedly reducing motivation and effort. High-profile cases like Anthony Rendon (who signed a $245M contract with the Los Angeles Angels after his 2019 World Series run, then immediately saw production decline) fuel this narrative. This analysis seeks to rigorously test whether this “contract effect” exists or if observed declines are attributable to other factors like aging or regression to the mean.\nStakeholders:\n\nMLB front offices and general managers evaluating contract extension decisions\nSports analytics professionals interested in player valuation\nFans and media seeking data-driven insights into player performance patterns\nAcademic researchers studying behavioral economics in professional sports\n\nSuccess Criteria:\n\nSuccessfully collect and clean multi-year salary and performance data for 100+ MLB players\nImplement statistical models that properly control for confounding factors (age, player quality, temporal trends)\nProvide clear, evidence-based conclusions about the existence and magnitude of any contract effect\nGenerate visualizations suitable for presentation to both technical and non-technical audiences\nProduce reproducible analysis pipeline for future research extensions"
  },
  {
    "objectID": "TechnicalReport.html#data-sources",
    "href": "TechnicalReport.html#data-sources",
    "title": "Technical Report",
    "section": "Data Sources",
    "text": "Data Sources\nPrimary dataset: Baseball Reference (https://www.baseball-reference.com)\n\nPlayer statistics (OPS, WAR) for MLB hitters, 2018-2025 seasons\nSalary data from Spotrac and Baseball Reference salary pages\nPlayer biographical information (age, position)\nCollected via custom Python web scraping package\n\nSupplementary data:\n\nContract signing dates and values verified against MLB Trade Rumors and ESPN reports\nPlayer transaction history to identify team changes concurrent with contracts\n\nData access notes:\n\nBaseball Reference data is publicly available but subject to their Terms of Service\nData collection performed in January 2025; salary data updates annually\nNo API available; data collected via web scraping with appropriate rate limiting\nAnalysis focuses on 2018-2025 to balance recency with sample size"
  },
  {
    "objectID": "TechnicalReport.html#methodology",
    "href": "TechnicalReport.html#methodology",
    "title": "Technical Report",
    "section": "Methodology",
    "text": "Methodology\n\n1. Data Acquisition\nPlayer Statistics Collection (batting_scraper.py):\nOur custom scraping pipeline collected batting statistics from Baseball Reference using the scrape_batting_data() function, which:\n\nIterates through eight season URLs (2018-2025) from Baseball Reference’s league-wide batting pages\nImplements browser-mimicking headers to avoid bot detection\nExtracts 34 statistical columns including OPS, WAR, and traditional batting metrics\nHandles the “TOT” (total) rows for players who changed teams mid-season, keeping only aggregated statistics\nApplies 1.2-second delays between requests to respect server load\nReturns structured data with player profile links for salary lookup\n\nThe function processed all MLB players with qualifying plate appearances, yielding 1,985 player-seasons across 300 unique players.\nSalary Data Collection (salary_scraper.py):\nSalary collection required a two-stage process due to Baseball Reference’s anti-scraping measures:\n\nLink Extraction: The extract_unique_links() function parsed the cleaned batting data to identify 300 unique player profile URLs, saving them with associated player names and IDs to unique_links.json\nSalary Scraping: The churn_with_cloudscraper() function used the cloudscraper library (which handles JavaScript challenges) to:\n\nParse HTML salary tables using parse_salary_table_from_soup(), which searches both visible tables and HTML comments (a common Baseball Reference pattern)\nExtract year-salary pairs for 2018-2025 where available\nImplement incremental saving to salaries.json with 4-second delays between requests\nResume capability if interrupted mid-scrape\nConvert nested JSON to tidy long-format CSV via salaries_json_to_csv()\n\n\nThis approach successfully collected salary data for all 300 players with a ~95% completion rate for available years.\n\n\n2. Cleaning Pipeline\nBatting Statistics Cleaning (batting_scraper.py):\nThe clean_batting_data() function performed the following transformations:\n\nConverted 23 statistical columns from strings to numeric types using pd.to_numeric() with error coercion\nRemoved aggregate rows (e.g., “MLB Average”)\nApplied minimum playing time filter: 100+ plate appearances per season\nExtracted batting hand indicators from player name suffixes (* = switch, # = left, default = right)\nStripped special characters from player names for consistent matching\nRemoved duplicate player-year combinations, keeping first occurrence\nDropped the Awards column (not needed for analysis)\n\nData Integration (analysis_package.py):\nThe load_and_merge_data() function:\n\nLoaded cleaned batting statistics and salary CSVs\nStandardized column names to lowercase for consistency\nPerformed left join on player name and year, preserving all batting records\nSaved merged dataset to MLB_2018_2025_Full.csv\n\nThe filter_players_with_multiple_seasons() function restricted analysis to players with 5+ seasons to ensure sufficient longitudinal data for mixed effects modeling (reduced dataset to 300 qualified players).\n\n\n3. Analysis Workflow\nContract Event Identification (analysis_package.py):\nThe create_contract_indicators() function engineered three key variables:\n\nbig_contract_year: Binary flag for salary increases exceeding 50% OR $5M absolute increase (identified 495 events)\nyears_from_contract: Integer offset from each player’s first big contract (e.g., -2, -1, 0, 1, 2…)\npost_contract: Binary indicator (0 = pre-contract, 1 = post-contract, NaN = no contract event)\n\nThis approach captures major contract signings while filtering noise from minor raises or team changes.\nStatistical Modeling (analysis_package.py):\nThe run_mixed_effects_models() function implemented two specifications using statsmodels.mixedlm():\nModel 1: Overall Salary-Performance Relationship\n\nFormula: ops ~ salary + war + year + (1|player)\nSample: All 1,590 player-seasons with complete data\nPurpose: Test whether higher salaries correlate with performance across the league\nRandom intercept structure accounts for player-specific baseline ability\n\nModel 2: Contract Effect with Controls\n\nFormula: ops ~ post_contract + age + year + (1|player)\nSample: 1,395 observations within ±3 years of contract signing (253 players)\nPurpose: Isolate post-contract performance change while controlling for:\n\nAge: Natural performance decline over career\nYear: League-wide temporal trends (e.g., changes in ball composition, rules)\nPlayer random effects: Individual baseline differences in ability\n\nEstimation: Maximum likelihood (REML=False) for model comparison compatibility\n\nRobustness Checks:\n\nAge-stratified analysis: Tested for differential effects across age groups (&lt;27, 27-30, 30+)\nInteraction models: Examined whether age moderates contract effects (post_contract * age_group)\nTemporal trend analysis: Tested for progressive decline using years_post as continuous predictor\nPaired t-tests: Within-player comparisons of pre/post means\n\nVisualization Generation (analysis_package.py):\nThe generate_visualizations() function produced publication-quality figures:\n\nPerformance trajectories with standard error bands showing ±3 years around contract\nBox plots comparing pre/post distributions for OPS and WAR\nAge distribution histogram at contract signing\nComprehensive multi-panel figure with spaghetti plots and change distributions\n\nAll plots saved as 300 DPI PNG files to plots/ directory.\n\n\n4. Tooling\nCore Dependencies:\n\npandas (2.0+): Data manipulation and merging\nnumpy: Numerical operations and missing data handling\nstatsmodels (0.14+): Mixed effects linear models (mixedlm)\nscipy: Statistical tests (t-tests, descriptive statistics)\nmatplotlib & seaborn: Static publication-quality visualizations\nbeautifulsoup4: HTML parsing for web scraping\nrequests: HTTP client for standard web requests\ncloudscraper: Cloudflare bypass for protected pages\naiohttp: Asynchronous HTTP (used in development, replaced by cloudscraper)\nstreamlit & plotly: Interactive dashboard (optional, for exploration)\n\nDevelopment Environment:\n\nPython 3.11.x\nVirtual environment (.venv) with isolated dependencies\nJupyter notebooks for exploratory analysis and model development\nModular package structure: separate modules for scraping, cleaning, and analysis\n\nReproducibility:\n\nComplete pipeline callable via single function: run_full_analysis() in analysis_package.py\nIntermediate outputs saved at each stage (cleaned stats, merged data, salary JSON)\nDeterministic scraping order via sorted player lists\nAll analysis code version-controlled in project repository\nData collection window: January 2025\nAnalysis executed: December 2025"
  },
  {
    "objectID": "TechnicalReport.html#results-diagnostics",
    "href": "TechnicalReport.html#results-diagnostics",
    "title": "Technical Report",
    "section": "Results & Diagnostics",
    "text": "Results & Diagnostics\n\nSummary Statistics and Descriptive Analysis\nOur analysis examined 1,985 player-seasons across 300 MLB players from 2018-2025, identifying 495 instances of “big contracts” defined as salary increases exceeding 50% or $5 million year-over-year. Descriptive statistics revealed an apparent performance decline following contract signings, with mean OPS decreasing from 0.765 to 0.745 (Δ = -0.020) and mean WAR declining from 2.113 to 1.872 (Δ = -0.241). Figure 1 displays the average performance trajectory around contract signing , while Figure 2 presents box plot comparisons of pre- and post-contract distributions.\n\n\n\n\n\n\n\n\n\n\n\n(a) Figure 1\n\n\n\n\n\n\n\n\n\n\n\n(b) Figure 2\n\n\n\n\n\n\n\nFigure 1: Performance comparison before and after contract signing\n\n\n\n\n\nMixed Effects Model Results\nTo account for player-specific baseline performance and temporal trends, we implemented mixed linear models with random intercepts for each player. Model 2, which focused on players within three years of contract signing (N=1,395 observations, 253 players), revealed that after controlling for age and temporal trends, the post-contract coefficient was non-significant (β = 0.011, p = 0.113, 95% CI: [-0.003, 0.025]). Critically, the age coefficient was negative and statistically significant (β = -0.004, p = 0.010), confirming that natural aging, not contract status, drives performance decline.\nPlayers typically sign their largest contracts between ages 28-31 (see Figure 3), coinciding with the onset of natural performance decline.\n\n\n\nFigure 3: Age at contract\n\n\nAmong the 253 players analyzed, 59.3% experienced performance declines after their contracts while 40.7% improved, indicating substantial individual variation. Age-stratified analysis showed older players (30+) had the largest descriptive decline (Δ = -0.036 OPS), while younger players (&lt;27) showed minimal change (Δ = -0.001 OPS). However, the interaction between post-contract status and age group was not statistically significant (p = 0.157), confirming that age itself—not the interaction with contract status—drives performance changes (see Figure 4).\n\n\n\nFigure 4: Age Analysis\n\n\n\n\nModel Diagnostics\nModel convergence was achieved with a log-likelihood of 1332.49. The variance components indicate substantial between-player variation (Group Var = 0.003), justifying the mixed effects approach over standard linear regression. The model achieved an R² of 0.66, with player fixed effects explaining the majority of performance variance (F = 7.23, p &lt; 0.001). Notably, temporal analysis revealed no evidence of progressive decline in years following contract signing (years_post coefficient = 0.002, p = 0.610), contradicting the hypothesis that players become increasingly complacent over time."
  },
  {
    "objectID": "TechnicalReport.html#discussion-next-steps",
    "href": "TechnicalReport.html#discussion-next-steps",
    "title": "Technical Report",
    "section": "Discussion & Next Steps",
    "text": "Discussion & Next Steps\n\nInterpretation of Results\nOur analysis reveals a notable discrepancy between descriptive statistics and model-based inference. While descriptive comparisons suggested contracts negatively impacted performance, the mixed effects model controlling for player-specific effects, age, and time trends found no statistically significant contract effect. This indicates that the observed descriptive decline is not causally related to contract signing itself, but rather reflects confounding factors that coincide with the timing of major contract negotiations.\nThe key insight is that the apparent performance decline following large contracts is primarily explained by natural aging patterns rather than any motivational or behavioral change induced by financial security. Players typically sign their largest contracts between ages 28-31, right when natural performance decline begins. The significant age coefficient (p = 0.010) combined with the non-significant contract coefficient (p = 0.113) demonstrates that age—not contract status—drives the observed performance changes. This suggests high-profile cases like Anthony Rendon’s post-contract decline represent outliers reflecting injury issues or player-specific circumstances rather than systematic motivational effects.\n\n\nLimitations\nSeveral limitations warrant consideration. First, our definition of “big contracts” (50% salary increase or $5M jump) may not capture all meaningful contract events, particularly for already highly-paid players. Second, we lack data on contract length, guaranteed money, and performance incentives, which may moderate the relationship between contracts and performance. Third, injury data was not systematically included; injuries could confound the relationship between age and performance. Fourth, our analysis period (2018-2025) may not capture longer-term career trajectories, particularly for players who signed contracts at the end of this window.\nAdditionally, survivor bias may affect our results—players who receive large contracts are already elite performers, potentially making them less susceptible to motivational decline. We also cannot fully disentangle regression to the mean from true performance changes, as players often sign contracts immediately following career-best seasons. Finally, our age control uses a linear specification, though performance decline may be non-linear (though our age-squared model showed similar results).\n\n\nFuture Research Directions\nSeveral avenues for future research emerge from this analysis:\n\nContract structure analysis: Examine how contract length, guaranteed money, and incentive clauses affect post-contract performance\nInjury integration: Incorporate detailed injury data to better separate age-related decline from injury-related decline\nPosition-specific effects: Investigate whether contract effects differ by position (e.g., pitchers vs. hitters, or by defensive position)\nTeam context: Analyze whether team quality, market size, or competitive pressure moderates contract effects\nComparison to other sports: Extend this methodology to NBA, NFL, or NHL data to test generalizability\nNon-linear aging models: Implement spline or polynomial age terms to better capture performance curve shapes\nCausal inference approaches: Apply propensity score matching or instrumental variables to strengthen causal claims\n\nThese extensions would provide a more comprehensive understanding of the complex relationship between compensation, motivation, and athletic performance in professional sports."
  }
]