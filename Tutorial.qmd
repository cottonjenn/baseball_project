---
title: "Getting Started"
jupyter: python3
---

Here is how you use my package:

```{python}
from bbanalysis import add

# print(add(2, 19))
```
have code that actually runs to demonstrate the package actually runs

```{python}
from bbanalysis import run_analysis_pipeline, run_cleaning_pipeling

# run_cleaning_pipeling()
# run_analysis_pipeline()
```

For the first part of the package use, we will import the first function for scraping the baseball hitting statistics. This will allow you to scrape the  players' statistics from the baseball-reference site.
```{python}
import sys
import os
sys.path.append(os.path.abspath("src"))
from bbanalysis.gathering_stats import scrape_batting_data

scrape_batting_data('https://www.baseball-reference.com/leagues/majors/2018-standard-batting.shtml')
```

Now we will do the second function which allows you to clean the data. Again, this is just the statistical data, not the salary data.
```{python}
from bbanalysis.gathering_stats import clean_batting_data

df = [1,2,3,4,5]
clean_batting_data(df)
```

This next set of functions from the package are for scraping and organizing the salary data into a nice dataset.

This first one is for creating headers, allowing you to access the data from over 1,000 individaul player pages, as that is the only way to access the salary data.
```{python}
from bbanalysis.gathering_salaries import create_http_headers

create_http_headers()
```

This next function is to parse the salary data from the players' pages and scrape it.
```{python}
from bs4 import BeautifulSoup
from bbanalysis.gathering_salaries import parse_salary_table_from_soup

html = """
<html>
<body>
<table id="br-salaries">
    <tr>
        <th>Year</th>
        <th>Salary</th>
    </tr>
    <tr>
        <td>2021</td>
        <td>$5,000,000</td>
    </tr>
    <tr>
        <td>2022</td>
        <td>$7,500,000</td>
    </tr>
</table>
</body>
</html>
"""

soup = BeautifulSoup(html, "html.parser")

result = parse_salary_table_from_soup(soup)
print(result)

```

At this point, you should now have scraped all the statistics data and have the setup for scraping the salary data. These following functions futher prepare and execute the scraping of the data from the actual player pages.

```{python}
form bbsalaries.gathering_salaries import scrape_salary_from_url
```

This function uses asyncio to actually scrape the data fromt he site, getting the information needed for the parse function to get the salaries from. 

```{python}
import pandas as pd
import json
from bbanalysis.gathering_links import extract_unique_links 

test_csv_path = "test_players.csv"
test_data = pd.DataFrame({
    "Player": ["Francisco Lindor"],
    "Player_Link": ["https://www.baseball-reference.com/players/l/lindofr01.shtml"]
})
test_data.to_csv(test_csv_path, index=False)

output_json_path = "test_players.json"

extract_unique_links(test_csv_path, output_json_path)

with open(output_json_path) as f:
    data = json.load(f)

print(json.dumps(data, indent=2))
```

This function is important becuase what it does is allow us to organize all the unique player links in one place. Many of the players in the data show up multiple times becuase they played more than one season over the six-year span, so this filters out repeat links.

```{python}
import cloudscraper
from bbanalysis.gathering_salaries import scrape_with_cloudscraper

scraper = cloudscraper.create_scraper()

url = "https://www.baseball-reference.com/players/l/lindofr01.shtml"

result = scrape_with_cloudscraper(url, scraper)
print(result)

```

Now with the scrape_salary_from_url function, you may already be able to scrape the salary data. However, due to rate limits it might be really difficult to scrape the data, and you might get errors. Using cloudscraper allows a user to implement their scraper while still maintaining speed and efficiency. Thus the scrape_with_cloudscraper function prepares us to use a cloudscraper. 

Next you will run this funciton:

```{python}
from bbanalysis.gathering_salaries import churn_with_cloudscraper
churn_with_cloudscraper()
```

This function implements the cloudscraper by creating one, then loops through the unique links dataset and scrapes all the salary data from 2018-2025 using scrape_with_cloudscraper. It then puts all the data into a .json file that stores the salary data. Once this finishes,you now have all the salary data from 2018-2025!

Now you just need to convert and organize the salary data properly to combine with the other statistical data into one big dataset. This function will organize it as necessary:

```{python}
from bbanalysis.gathering_salaries import salaries_json_to_csv
salaries_json_to_csv("salaries.json", "salaries.csv")
```

Now we'll combine both the datasets using this function:

```{python}
import pandas as pd
from bbanalysis.gathering_salaries import load_and_merge_data

stats_test = pd.DataFrame({
    "Player": ["Mike Trout", "Aaron Judge"],
    "Year": [2021, 2021],
    "HR": [45, 39],
    "RBI": [104, 98]
})
stats_csv_path = "test_stats.csv"
stats_test.to_csv(stats_csv_path, index=False)

salaries_test = pd.DataFrame({
    "player": ["Mike Trout", "Aaron Judge"],
    "year": [2021, 2021],
    "salary": [5000000, 3000000]
})
salaries_csv_path = "test_salaries.csv"
salaries_test.to_csv(salaries_csv_path, index=False)

merged_df = load_and_merge_data(stats_csv_path, salaries_csv_path, "test_merged.csv")

print(merged_df)

```

And now we're ready to do our analysis!

The first thing we will do is filter out players who ahve less than five seasons in the dataset, because we want to compare how salary affects play and it is hard to make significant findings otherwise.

```{python}
import pandas as pd
from bbanalysis.gathering_salaries import filter_players_with_multiple_seasons

test_data = pd.DataFrame({
    "player": ["A", "A", "A", "B", "B", "C", "C", "C", "C", "C"],
    "year": [2018, 2019, 2020, 2019, 2020, 2016, 2017, 2018, 2019, 2020],
    "HR": [10, 12, 15, 5, 6, 20, 22, 25, 18, 19]
})

filtered_df = filter_players_with_multiple_seasons(test_data, min_seasons=3)

print(filtered_df)

```

This function filters these players out. 
Next we will create indicators that mark when a player signs a big contract, leading to a large boost in pay. We will define an increase in $5,000,000 in salary as representative of this. 
```{python}
import pandas as pd
import numpy as np
from bbanalysis.analysis import create_contract_indicators

test_data = pd.DataFrame({
    "player": ["A", "A", "A", "B", "B", "C", "C", "C"],
    "year": [2018, 2019, 2020, 2019, 2020, 2018, 2019, 2020],
    "salary": [1_000_000, 1_200_000, 2_500_000, 500_000, 700_000, 2_000_000, 2_100_000, 2_300_000]
})

df_with_contracts = create_contract_indicators(test_data, pct_threshold=0.5, abs_threshold=1_000_000)

print(df_with_contracts)

```

Now that we have this created, we can effectively compare statistical performance with before and after a large contract signing. One way to effectively do this is to run mixed effects models. We have a function for this:

```{python}
import pandas as pd
import numpy as np
from bbanalysis.analysis import run_mixed_effects_models

test_data = pd.DataFrame({
    "player": ["A", "A", "A", "B", "B", "B", "C", "C", "C"],
    "year": [2018, 2019, 2020, 2018, 2019, 2020, 2018, 2019, 2020],
    "salary": [1_000_000, 1_200_000, 2_500_000, 500_000, 700_000, 700_000, 2_000_000, 2_100_000, 2_300_000],
    "ops": [0.800, 0.850, 0.900, 0.700, 0.720, 0.710, 0.750, 0.760, 0.770],
    "war": [5, 6, 7, 2, 3, 3, 4, 4, 5],
    "years_from_contract": [-1, 0, 1, np.nan, np.nan, np.nan, -1, 0, 1],
    "post_contract": [0, 1, 1, np.nan, np.nan, np.nan, 0, 1, 1],
    "age": [24, 25, 26, 22, 23, 24, 28, 29, 30]
})

results = run_mixed_effects_models(test_data, window_years=1)

print("\nModel 1 summary:")
if 'model1' in results:
    print(results['model1'].summary())

print("\nModel 2 summary:")
if 'model2' in results:
    print(results['model2'].summary())

print("\nRestricted df for Model 2:")
print(results.get('df_model2'))

```

From these mixed effects models we can glean valuable information, like does performance increase or decrease with salary increase or decrease over time, and whether a steep increase in salary can have a big impact on a player's performance.

The next step would be visualizing the data through using this function:

```{python}
import pandas as pd
import numpy as np
import os
from bbanalysis.analysis import generate_visualizations

test_data = pd.DataFrame({
    "player": ["A", "A", "A", "B", "B", "B", "C", "C", "C"],
    "year": [2018, 2019, 2020, 2018, 2019, 2020, 2018, 2019, 2020],
    "ops": [0.800, 0.850, 0.900, 0.700, 0.720, 0.710, 0.750, 0.760, 0.770],
    "war": [5, 6, 7, 2, 3, 3, 4, 4, 5],
    "years_from_contract": [-1, 0, 1, np.nan, np.nan, np.nan, -1, 0, 1],
    "post_contract": [0, 1, 1, np.nan, np.nan, np.nan, 0, 1, 1]
})

output_dir = "test_plots"
if os.path.exists(output_dir):
    import shutil
    shutil.rmtree(output_dir)

generate_visualizations(test_data, output_dir=output_dir)

print("Files in output directory:", os.listdir(output_dir))

```

Now we can put it all together with this function:

```{python}
from bbanalysis.analysis import run_full_analysis

results = run_full_analysis(
    stats_path="test_stats.csv",       
    salary_path="test_salaries.csv",   
    min_seasons=3,                     
    output_dir="test_full_analysis_plots"
)

```

This allows us to implement all of these other functions into one full, effective analysis.




